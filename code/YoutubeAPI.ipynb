{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmMR8IJ5SRHt"
      },
      "source": [
        "# Get IDs from Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p168TmmNST-a"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DQKuU9CeTReT"
      },
      "outputs": [],
      "source": [
        "youtube = build('youtube', 'v3', developerKey=os.environ[\"YOUTUBE_API_KEY\"])\n",
        "\n",
        "res =  youtube.channels().list(id='UC16niRr50-MSBwiO3YDb3RA', #Copy and paste here ID channel\n",
        "                               part='contentDetails').execute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvS8WRZ5TcEy",
        "outputId": "8470667a-62c3-4b0c-ed9f-65c73fbe76d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'kind': 'youtube#channelListResponse',\n",
              " 'etag': 'sZ-Jnqk906RCqYi5ZLpfqZ81N9M',\n",
              " 'pageInfo': {'totalResults': 1, 'resultsPerPage': 5},\n",
              " 'items': [{'kind': 'youtube#channel',\n",
              "   'etag': '3tLMxTHqqlpjJBE5lOA_XOLIkhQ',\n",
              "   'id': 'UC16niRr50-MSBwiO3YDb3RA',\n",
              "   'contentDetails': {'relatedPlaylists': {'likes': '',\n",
              "     'uploads': 'UU16niRr50-MSBwiO3YDb3RA'}}}]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Get upload playlist\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyDpv7JfSl6R"
      },
      "source": [
        "# Extract comments and other variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BN9HN_UtSY1_"
      },
      "outputs": [],
      "source": [
        "# Get the Playlist ID from res. Here the paylist is uploads. All the upload content.\n",
        "playlist_ids = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F5uLfSivVLZi"
      },
      "outputs": [],
      "source": [
        "playlist_ids = ['PL6XRrncXkMaUNhifXWtS3gZtctnZpUZPw']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QhQwcdwSPhjq"
      },
      "outputs": [],
      "source": [
        "def get_all_video_ids_from_playlists(youtube, playlist_ids):\n",
        "    all_videos = []  # Initialize a single list to hold all video IDs\n",
        "\n",
        "    for playlist_id in playlist_ids:\n",
        "        next_page_token = None\n",
        "\n",
        "        # Fetch videos from the current playlist\n",
        "        while True:\n",
        "            playlist_request = youtube.playlistItems().list(\n",
        "                part='contentDetails',\n",
        "                playlistId=playlist_id,\n",
        "                pageToken=next_page_token)\n",
        "            playlist_response = playlist_request.execute()\n",
        "\n",
        "            for item in playlist_response['items']:\n",
        "                video_id = item['contentDetails']['videoId']\n",
        "                video_request = youtube.videos().list(\n",
        "                    part='contentDetails',\n",
        "                    id=video_id\n",
        "                )\n",
        "                video_response = video_request.execute()\n",
        "                duration = video_response['items'][0]['contentDetails']['duration']\n",
        "\n",
        "                # Check if the video is not a short (you can adjust the duration threshold as needed)\n",
        "                if 'M' in duration or 'H' in duration:\n",
        "                    all_videos.append(video_id)\n",
        "\n",
        "            next_page_token = playlist_response.get('nextPageToken')\n",
        "\n",
        "            if next_page_token is None:\n",
        "                break\n",
        "\n",
        "    return all_videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-khyA3uZP2sb"
      },
      "outputs": [],
      "source": [
        "video_ids = get_all_video_ids_from_playlists(youtube, playlist_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNr52bsgQDwK",
        "outputId": "86ae9e36-0d38-4bda-c8f8-bb851615ea8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['QbpxLZGLMGs',\n",
              " 'E-5Zf4D5jmI',\n",
              " 'v_UZjVMcOkk',\n",
              " 'JCAza8k6CyI',\n",
              " '5OTXiFtbpjQ',\n",
              " 'djCKmQVkftY',\n",
              " 'VNZgfKiv__o',\n",
              " '-VuuL_AYvVs',\n",
              " 'uk-ZzeC96BM',\n",
              " '5F6YRQKZX9E',\n",
              " 'y8Cg3LwIcZk',\n",
              " '65CI8hznDy4',\n",
              " 'YC4CXDAsgTo',\n",
              " 'AnCatG15hOM',\n",
              " 'UyFSa_0ei48',\n",
              " 'jHfrf_DGTGE',\n",
              " 'vwvwpn0fays',\n",
              " 'KQTKy64PuOE',\n",
              " 'ZJShiSyRLVg',\n",
              " 'HuKo31IFAt0',\n",
              " 'urmDcQKB8eY',\n",
              " 'q3nMcZRFHSs',\n",
              " 'WeKjWxwy5jI',\n",
              " 'x8losEBzCtU',\n",
              " 'fWKeCfbPqv8',\n",
              " '8FjvJxxlFtI',\n",
              " 'tJWTd8O1oKk',\n",
              " 'frFnqQ9Jajg',\n",
              " 'zApjeJtB6gI',\n",
              " 'n9IrowRkGFE',\n",
              " 'M_NsHTOL258',\n",
              " 'QkxXpCiYI0U',\n",
              " 'rBydMHT8tVU',\n",
              " 'Fvziacme9XI',\n",
              " 'm8qfD5nWSec',\n",
              " 'BQaJX26wgnQ',\n",
              " 'ri-Lvmfzf2s',\n",
              " '7w6c6oGs2_w',\n",
              " 'FccwpafufPQ',\n",
              " 'KSNs8P3MrMY',\n",
              " 'R5MJz1-dMQ4',\n",
              " 'hrG1VqDQhBQ',\n",
              " 'zdCqSi0KH2c',\n",
              " 'g0BlDeU8rlE',\n",
              " '9OrrLvXpmKo',\n",
              " 'ZX_dFwCaX-4']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "le5hDo9GSatf"
      },
      "outputs": [],
      "source": [
        "def get_all_video_ids_from_playlists(youtube, playlist_ids):\n",
        "    all_videos = []  # Initialize a single list to hold all video IDs\n",
        "\n",
        "    for playlist_id in playlist_ids:\n",
        "        next_page_token = None\n",
        "\n",
        "        # Fetch videos from the current playlist\n",
        "        while True:\n",
        "            playlist_request = youtube.playlistItems().list(\n",
        "                part='contentDetails',\n",
        "                playlistId=playlist_id,\n",
        "                pageToken=next_page_token)\n",
        "            playlist_response = playlist_request.execute()\n",
        "\n",
        "            all_videos += [item['contentDetails']['videoId'] for item in playlist_response['items']]\n",
        "\n",
        "            next_page_token = playlist_response.get('nextPageToken')\n",
        "\n",
        "            if next_page_token is None:\n",
        "                break\n",
        "\n",
        "    return all_videos\n",
        "\n",
        "# Fetch all video IDs from the specified playlists\n",
        "video_ids = get_all_video_ids_from_playlists(youtube, playlist_ids)\n",
        "\n",
        "# Now we can pass video_ids to the next function\n",
        "# next_function(video_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__ptzYjjSoHt",
        "outputId": "b79c1b45-7b2a-4687-91dc-610d656e5b23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(video_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Xlax0JZu9k"
      },
      "source": [
        "## Get the comments of videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ55zSfma5zY",
        "outputId": "29d370e1-5dbc-49e7-d926-510f4333e409"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "box = [['Video Title', 'Name', 'Comment', 'Time', 'Likes', 'Reply Count']]\n",
        "\n",
        "def scrape_comments_with_replies(video_id):\n",
        "    try:\n",
        "        video_info = youtube.videos().list(part='snippet', id=video_id).execute()\n",
        "        video_title = video_info['items'][0]['snippet']['title']\n",
        "    except HttpError as e:\n",
        "        if e.resp.status == 403:\n",
        "            print(f\"Comments are disabled for video {video_id}. Skipping...\")\n",
        "            return None\n",
        "        else:\n",
        "            print(f\"An error occurred while fetching video info for video {video_id}: {e}\")\n",
        "            return None\n",
        "\n",
        "    try:\n",
        "        data = youtube.commentThreads().list(part='snippet', videoId=video_id, maxResults='100', textFormat=\"plainText\").execute()\n",
        "    except HttpError as e:\n",
        "        if e.resp.status == 403:\n",
        "            print(f\"Comments are disabled for video {video_id}. Skipping...\")\n",
        "            return None\n",
        "        else:\n",
        "            print(f\"An error occurred while fetching comments for video {video_id}: {e}\")\n",
        "            return None\n",
        "\n",
        "    for i in data[\"items\"]:\n",
        "        name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
        "        comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
        "        published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
        "        likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
        "        replies = i[\"snippet\"]['totalReplyCount']\n",
        "\n",
        "        box.append([video_title, name, comment, published_at, likes, replies])\n",
        "\n",
        "        totalReplyCount = i[\"snippet\"]['totalReplyCount']\n",
        "\n",
        "        if totalReplyCount > 0:\n",
        "            parent = i[\"snippet\"]['topLevelComment'][\"id\"]\n",
        "\n",
        "            try:\n",
        "                data2 = youtube.comments().list(part='snippet', maxResults='100', parentId=parent, textFormat=\"plainText\").execute()\n",
        "            except HttpError as e:\n",
        "                print(f\"An error occurred while fetching replies for comment {parent} of video {video_id}: {e}\")\n",
        "                continue\n",
        "\n",
        "            for i in data2[\"items\"]:\n",
        "                name = i[\"snippet\"][\"authorDisplayName\"]\n",
        "                comment = i[\"snippet\"][\"textDisplay\"]\n",
        "                published_at = i[\"snippet\"]['publishedAt']\n",
        "                likes = i[\"snippet\"]['likeCount']\n",
        "                replies = ''\n",
        "\n",
        "                box.append([video_title, name, comment, published_at, likes, replies])\n",
        "\n",
        "    while (\"nextPageToken\" in data):\n",
        "        try:\n",
        "            data = youtube.commentThreads().list(part='snippet', videoId=video_id, pageToken=data[\"nextPageToken\"], maxResults='100', textFormat=\"plainText\").execute()\n",
        "        except HttpError as e:\n",
        "            print(f\"An error occurred while fetching next page of comments for video {video_id}: {e}\")\n",
        "            break\n",
        "\n",
        "        for i in data[\"items\"]:\n",
        "            name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
        "            comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
        "            published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
        "            likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
        "            replies = i[\"snippet\"]['totalReplyCount']\n",
        "\n",
        "            box.append([video_title, name, comment, published_at, likes, replies])\n",
        "\n",
        "            totalReplyCount = i[\"snippet\"]['totalReplyCount']\n",
        "\n",
        "            if totalReplyCount > 0:\n",
        "                parent = i[\"snippet\"]['topLevelComment'][\"id\"]\n",
        "\n",
        "                try:\n",
        "                    data2 = youtube.comments().list(part='snippet', maxResults='100', parentId=parent, textFormat=\"plainText\").execute()\n",
        "                except HttpError as e:\n",
        "                    print(f\"An error occurred while fetching replies for comment {parent} of video {video_id}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                for i in data2[\"items\"]:\n",
        "                    name = i[\"snippet\"][\"authorDisplayName\"]\n",
        "                    comment = i[\"snippet\"][\"textDisplay\"]\n",
        "                    published_at = i[\"snippet\"]['publishedAt']\n",
        "                    likes = i[\"snippet\"]['likeCount']\n",
        "                    replies = ''\n",
        "\n",
        "                    box.append([video_title, name, comment, published_at, likes, replies])\n",
        "\n",
        "    df = pd.DataFrame({'Video Title': [i[0] for i in box], 'Name': [i[1] for i in box], 'Comment': [i[2] for i in box],\n",
        "                       'Time': [i[3] for i in box], 'Likes': [i[4] for i in box], 'Reply Count': [i[5] for i in box]})\n",
        "\n",
        "    return df\n",
        "\n",
        "# Iterate over video IDs and save comments in a single file\n",
        "all_comments = pd.DataFrame()\n",
        "for video_id in video_ids[0:1]:\n",
        "    comments_df = scrape_comments_with_replies(video_id)\n",
        "    if comments_df is not None:\n",
        "        all_comments = pd.concat([all_comments, comments_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successful! Check the CSV file that you have just created.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Save the comments\n",
        "all_comments.to_csv('../data/test_youtube_comments.csv', index=False)\n",
        "\n",
        "print(\"Successful! Check the CSV file that you have just created.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
